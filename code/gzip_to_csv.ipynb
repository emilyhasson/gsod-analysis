{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98S74FneeXQ7"
      },
      "source": [
        "#### Loading Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjpXzd-1dWNQ"
      },
      "outputs": [],
      "source": [
        "# !pip install alive_progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_7d2bf_aSUF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import tarfile\n",
        "import gzip\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from alive_progress import alive_bar\n",
        "import multiprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcehKE3ueZte"
      },
      "source": [
        "---\n",
        "\n",
        "#### Gathering Data from `.gzip` Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lAUC81lc5XZ"
      },
      "outputs": [],
      "source": [
        "def gzip_to_dataframe(gz_file):\n",
        "\n",
        "    try:\n",
        "        # read in file as fixed-width file (FWF)\n",
        "        df = pd.read_fwf(gzip.open(gz_file))\n",
        "\n",
        "        # focus on observations with recorded date\n",
        "        df = df[df['YEARMODA'].notna()]\n",
        "\n",
        "        # locate and filter out coded missing values (e.g. 9999, 99.99, 99999.9)\n",
        "        df_without_year = df.drop(columns='YEARMODA').astype('str'\n",
        "        ).replace(to_replace=r'[9]+[.]+[9]*', value=np.nan, regex=True\n",
        "        ).dropna(axis=1, how='all')\n",
        "        \n",
        "        df = pd.concat([df_without_year, df['YEARMODA']], axis=1)\n",
        "\n",
        "        # remove attributes with unnamed columns (these columns strictly count how many\n",
        "        # observations were used when calculating the observed mean)\n",
        "        df = df.drop(columns=df.columns[df.columns.str.startswith('Unnamed')]).fillna(0.0)\n",
        "\n",
        "        # extract date information and save into separate columns\n",
        "        df[['year', 'month', 'day']] = pd.to_datetime(df['YEARMODA'], format='%Y%m%d'\n",
        "        ).astype('str').str.split('-', expand=True).astype('int64')\n",
        "\n",
        "        if df['FRSHTT'].astype('int64').sum() != 0:\n",
        "            df[['fog', 'rain', 'snow', 'hail', 'thunder', 'tornado']] = df['FRSHTT'].astype('int64'\n",
        "            ).replace({0:'000000'}).astype(str).apply(list).apply(pd.Series\n",
        "            ).fillna(0).astype(int)\n",
        "        else:\n",
        "            df[['fog', 'rain', 'snow', 'hail', 'thunder', 'tornado']] = np.zeros(shape=(df.shape[0], 6)).astype(int)\n",
        "\n",
        "        # extract precipitation values and flags and store in respective columns\n",
        "        df[['precip_in', 'precip_flag']] = df['PRCP'].str.extract('(?P<precip_in>[\\d.]{4})(?P<precip_flag>[A-Z]{1})'\n",
        "        ).fillna({'precip_in':0, 'flag':np.nan})\n",
        "        \n",
        "        df['precip_in'] = df['precip_in'].astype('float64')\n",
        "\n",
        "        # replace pointless flags fro temperature columns\n",
        "        df['max_temp_frnht'] = df['MAX'].apply(lambda x: str(x).replace('*', '')).astype('float64')\n",
        "        df['min_temp_frnht'] = df['MIN'].apply(lambda x: str(x).replace('*', '')).astype('float64')\n",
        "        \n",
        "        # remove columns we just extracted data from and rename columns\n",
        "        df.drop(columns=['FRSHTT', 'YEARMODA', 'MAX', 'MIN', 'PRCP', 'WBAN'], inplace=True)\n",
        "        df.rename(columns={\n",
        "            'STN---':'station_num',\n",
        "            'TEMP':'temp_ft',\n",
        "            'DEWP':'dewpt_ft',\n",
        "            'SLP':'slp_mb',\n",
        "            'VISIB':'visib_mi',\n",
        "            'GUST':'max_gust_knt',\n",
        "            'SNDP':'snow_depth_in',\n",
        "            'WDSP':'wind_knt',\n",
        "            'MXSPD':'maxwind_knt'\n",
        "        }, inplace=True)\n",
        "\n",
        "        # reorder columns and return dataframe\n",
        "        beg_cols = ['station_num', 'year', 'month', 'day']\n",
        "        end_cols = ['precip_in', 'precip_flag']\n",
        "        mid_cols = list(df.columns[~df.columns.isin(beg_cols + end_cols)])\n",
        "\n",
        "        return df#[beg_cols + mid_cols + end_cols]\n",
        "    \n",
        "    except:\n",
        "      pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVFoUT-eekgP"
      },
      "source": [
        "---\n",
        "\n",
        "#### File Management"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "220hMpGvcnHi"
      },
      "outputs": [],
      "source": [
        "def spew_out_year_directory(year):\n",
        "    gsod_dir = f'.'\n",
        "    year_tar_dir = list(filter(lambda x: str(year) in x, os.listdir(gsod_dir)))[0]\n",
        "    if tarfile.is_tarfile(f'{gsod_dir}/{year_tar_dir}'):\n",
        "        with tarfile.open(f'{gsod_dir}/{year_tar_dir}') as tar:\n",
        "            tar.extractall(path=f'./{year}_data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9v-oQJCcpDm"
      },
      "outputs": [],
      "source": [
        "def gather_year_directory_data(year, n_samples):\n",
        "    \n",
        "    spew_out_year_directory(year)\n",
        "    assert os.path.isdir(f'./{year}_data'), f'./{year}_data not valid directory'\n",
        "    \n",
        "    df_dict = {}\n",
        "    dir_files = os.listdir(f'./{year}_data')\n",
        "    if n_samples > len(dir_files):\n",
        "      n_samples = len(dir_files)\n",
        "    \n",
        "    with alive_bar(n_samples, title=f'Working on {year} ...') as bar:\n",
        "        for sample in random.sample(population=range(len(dir_files)), k=n_samples):\n",
        "            try:\n",
        "                gz_file = dir_files[sample]\n",
        "                df_dict[gz_file[:gz_file.find('-')]] = gzip_to_dataframe(f'./{year}_data/{gz_file}')\n",
        "                os.remove(f'./{year}_data/{gz_file}')\n",
        "                bar()\n",
        "            except:\n",
        "                continue\n",
        "    \n",
        "    return df_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Arsh5MXScrbn"
      },
      "outputs": [],
      "source": [
        "def write_to_csv(year, n_samples):\n",
        "    \n",
        "    # gather dataframes for given year\n",
        "    agg_df_dict = gather_year_directory_data(year, n_samples)\n",
        "\n",
        "    for file in os.listdir(f'./{year}_data'):\n",
        "      if file.endswith('.gz'):\n",
        "        os.remove(f'./{year}_data/{file}')\n",
        "    \n",
        "    # write valid stations to text file for retrieval later on\n",
        "    with open(f'./{year}_data/{year}stations.txt', 'w') as st_file:\n",
        "        total_stations = 0\n",
        "        for st in agg_df_dict.keys():\n",
        "            total_stations += 1\n",
        "            st_file.write(st + '\\n')\n",
        "    \n",
        "    # write to concatenated dataframe to corresponding year folder\n",
        "    pd.concat(\n",
        "        agg_df_dict.values()\n",
        "        ).to_csv(f'./{year}_data/{year}weatherdata.csv')\n",
        "\n",
        "    # log results\n",
        "    if os.path.isfile(f'./{year}_data/{year}stations.txt'):\n",
        "        print(f'>> Total stations: {total_stations}/{n_samples}')\n",
        "    if os.path.isfile(f'./{year}_data/{year}weatherdata.csv'):\n",
        "        print(f'>> Success: {year}weatherdata.csv written to ./{year}_data/')\n",
        "    else:\n",
        "        print(f'!! Failure: {year}weatherdata.csv NOT written to ./{year}_data/')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J0t8IHYeons"
      },
      "source": [
        "---\n",
        "\n",
        "#### Running ( + Trusting) the Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2qJprB8g_9u",
        "outputId": "d6bd2c84-cabd-46ac-8b59-27253749d53a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working on 2001 ... |████████████████████████████████████████| 9008/9008 [100%] in 18:42.6 (8.02/s) \n",
            ">> Total stations: 8999/10000\n",
            ">> Success: 2001weatherdata.csv written to ./2001_data/\n",
            "Working on 2005 ... |████████████████████████████████████████| 10000/10000 [100%] in 22:07.1 (7.54/s) \n",
            ">> Total stations: 9009/10000\n",
            ">> Success: 2005weatherdata.csv written to ./2005_data/\n",
            "Working on 2006 ... |████████████████████████████████████████| 9463/9463 [100%] in 21:36.7 (7.30/s) \n",
            ">> Total stations: 9409/10000\n",
            ">> Success: 2006weatherdata.csv written to ./2006_data/\n",
            "Working on 2007 ... |████████████████████████████████████████| 9766/9766 [100%] in 22:05.5 (7.37/s) \n",
            ">> Total stations: 9634/10000\n",
            ">> Success: 2007weatherdata.csv written to ./2007_data/\n"
          ]
        }
      ],
      "source": [
        "start_year = 2001\n",
        "end_year = 2007\n",
        "n_samples = 10000\n",
        "\n",
        "for year in range(start_year, end_year + 1):\n",
        "  if year in [2002, 2003, 2004]:\n",
        "    continue\n",
        "  if f'{year}_data' in os.listdir():\n",
        "    shutil.rmtree(f'{year}_data')\n",
        "  write_to_csv(year, n_samples)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "gzip_to_csv.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}