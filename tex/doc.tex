\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Challenges of Big Data: Predicting Occurrence of Storm Types per Historical Data}
\author{
\IEEEauthorblockN{Erens, Sam}
\IEEEauthorblockA{
  \textit{Department of Mathematics} \\
  \textit{Department of Statistics} \\
  \textit{University of Illinois, Champaign} \\
  Champaign, IL, United States \\
  serens2@illinois.edu
}
\and
\IEEEauthorblockN{Hasson, Emily}
\IEEEauthorblockA{
  \textit{Department of Computer Science} \\
  \textit{Department of Statistics} \\
  \textit{University of Illinois, Champaign} \\
  Champaign, IL, United States \\
  ehasson2@illinois.edu
}
\and
\IEEEauthorblockN{Nelson, Lucas}
\IEEEauthorblockA{
  \textit{Department of Economics} \\
  \textit{Department of Statistics} \\
  \textit{University of Illinois, Champaign}\\
  Champaign, IL, United States \\
  lln2@illinois.edu}
}

\maketitle

\begin{abstract}

In this paper, we address the challenges in collecting, cleaning, and analyzing gigabytes of archived weather data. Using historical weather data provided by NOAA, we apply an array of statistical models to classify the occurrence of a specific weather event. Using popular software of the field, our findings contribute to an immensely extensive body of literature of weather classification techniques.

\end{abstract}

\begin{IEEEkeywords}
big data, spatiotemporal data, logistic regression
\end{IEEEkeywords}

\section{Introduction}

Emily's work goes here ...

\section{Related Work}

Weather forecasting has proven to be a difficult task, both in retrospective analysis and unobserved forecasting, due to the massive amounts of data required for an analysis and possible repercussions of an inaccurate forecast. As a result, researchers have drawn from other fields to help manage the ingestion of massive, multidimensional data [Sahasrabuddhe et al, 51; Mittal and Sangwan, 2019; Hassani and Silva, (53)], relying on clustering and dimensionality reduction techniques to derive patterns and remove noise or outliers among less-computationally expensive subsets of weather data. These results have allowed others to design and refine models that adapt to the changing climate [Vannitsem et al., 56] and are more robust and statistically significant when presented with the problem of frequent climate changes.

However, even with the aforementioned advances in the field, weather forecasting remains a challenging issue that holds heavy implications in the case of an inaccurate or misleading forecast. Businesses and industries that predominantly operate outdoors rely on the accuracy of forecasts, both short-term and long-term, as it has a direct effect on their profits [Jain and Jain, 2017], allowing for these businesses to better manage costs of operation well before they could otherwise [Reddy and Babu, 2017].

Our analysis makes use of the previous findings, and we aim to add to this existing body of literature by demonstrating these difficulties in gathering weather data as well as composing a meaningful analysis from massive, multidimensional weather-related data.

\section{Data}

For our project, we will be working with structured weather data provided by various weather-related government agencies\footnote{Archived dataset can be found on Kaggle: \textit{NOAA Global Surface Summary of the Day} (see References)}, including the National Oceanic and Atmospheric Administration (NOAA) and National Climate and Environmental Institution (NCEI), gathered by each of the internationally distributed sensors from the beginning of 1901 to the end of 2019. Each of these sensors report basic logging information (e.g., datetime and station identification) - which can be merged with provided text files in the same archive that provide geographical information (latitude, longitude, named location) of each station - as well as climate data on a daily basis (e.g., mean temperature (F), dew point (F), natural disaster indicators, etc.). Although the entire archive spans 120 years, we will strictly be focusing on data generated beyond 1975, the year the NOAA decided to increase the number of sensors they deploy. Altogether, this sample of the original archives contains 23GB of data comprised of NN million observations with 23 attributes each.

Prior to conducting our analyses below, we did not perform any preprocessing to our data. However, this does not mean that the data was prepared ready for analysis. Rather, only after iterating over each year's series of `.gz` files were we able to prepare our dataset for analysis, including mapping a uniform null value to various missing value codes, expanding cluttered columns into multiple columns, and condensing each station's annual report to a single annual report. (Table 1 in the Appendix shows the first five and last five observations of the resulting dataset.) Given this, we will conduct k-fold cross validation on samples of our dataset below in our logistic regression models to allow hyperparameter selection to determine our best model.

\section{Preliminary Technical Details and Results}


For the first phase of the project, we will fit a logistic regression model to the dataset to predict the presence or absence of a tornado at each weather station using most, if not all, of the other variables in the dataset as predictors. Currently, we have one model fit to the 1975 dataset that appears to be doing quite well; however, there is only one tornado recorded for 1975 so perhaps this is due to chance. We would like to expand our analysis to the years 1975 to 2019 and create separate logistic regression models for each of the four regions of the U.S. (Northeast, Midwest, West, and South).\footnote{https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us\_regdiv.pdf} \\

The model is quite simple in principle. As we learned in class, logistic regression uses numeric predictor variables to predict the outcome of a zero-one binary response variable. In this case, the response variable is the presence or absence of a tornado, but logistic regression  models have also been used in the past to predict credit card default and detect malignancy in cancer patients. Things get a little bit more complicated when you are working with multiple predictor variables rather than a single predictor, but the underlying principle is the same.\footnote{https://en.wikipedia.org/wiki/Logistic\_regression} \\

There were no tornados in our dataset and the model predicted no tornados. Therefore, the misclassification rate is zero.\footnote{https://github.com/emilyhasson/gsod-analysis/blob/main/gsod-analysis-part-1.ipynb} \\

Going forward, we hope to have predictions for the entire period from 1975 to 2019 by Friday, April 29th. We will then focus on developing separate models for each geographic region of the United States. We hope to be finished with the modeling portion of the project no later than Friday, May 6th so that we can spend the final week analyzing the results and editing the video presentation. Our progress thus far can be found in our GitHub.\footnote{https://github.com/emilyhasson/gsod-analysis}\\

\begin{thebibliography}{9}

\bibitem{article}
Jain H, Jain R (2017). \textit{Big data in weather forecasting: applications and challenges.} In: 2017 International conference on big data analytics and computational intelligence (ICBDAC). pp 138–142

\bibitem{article}
Reddy PC, Babu AS (2017). \textit{Survey on weather prediction using big data analystics.} In: 2017 Second international conference on electrical, computer and communication technologies (ICECCT). pp 1–6

\bibitem{article}
Mittal S, Sangwan OP (2019). \textit{Big data analytics using data mining techniques: a survey.} In: Advanced informatics for computing research, Singapore. Springer Singapore, pp 264–273

\bibitem{article}
Sahasrabuddhe DV, Jamsandekar P (2015). \textit{Data structure for representation of big data of weather forecasting: a review.} Int J Comput Sci Trends Technol IJCST 3(6):48–56

\bibitem{article}
Hassani H, Silva ES (2015). \textit{Forecasting with big data: a review.} Ann Data Sci 2(1):5–19

\bibitem{article}
Vannitsem S et al (2021). \textit{Statistical postprocessing for weather forecasts: review, challenges, and avenues in a big data world.} Bull Am Meteorol Soc 102(3):E681–E699

\end{thebibliography}

\section{Contributions}

\begin{itemize}
\item \textbf{Emily}:
\item \textbf{Lucas}: Designed scripts that gather annual data from archived .tar/.gz files, returning analysis-ready .csv files of each station in a given year. Wrote out Data, Related Work, and References section.
\item \textbf{Sam}:
\end{itemize}

\section{Appendix}

\begin{table}[h!]
\centering
 \begin{tabular}{||c c c c c c||}
 \hline
  Station& Datetime &Temperature & \dots & Precip Flag \\ [0.5ex]
 \hline\hline
 725130 & 19750101 & 34.8 & \dots & G \\
 725130 & 19750102 & 31.4 & \dots & G \\
 725130 & 19750103 & 26.0 & \dots & G \\
 725130 & 19750104 & 34.8 & \dots & G \\
 \dots & \dots & \dots & \dots & \dots \\
 702310 & 20191227 & -16.4 & \dots & I \\
 702310 & 20191228 & -5.7 & \dots & G \\
 702310 & 20191229 & 0.6 & \dots & G \\
 702310 & 20191230 & -20.8 & \dots & A \\
 702310 & 20191231 & -16.3 & \dots & A \\[1ex]

 \hline
 \end{tabular}
 \caption{Sample of final dataset}
\end{table}

\end{document}
